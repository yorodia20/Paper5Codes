{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a Georeferenced Road Accident Database in Senegal: Automatic Data Extraction and GIS Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIRST PART: Data Collection from SENENEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pour le database\n",
    "import requests    # pour envoyer une requete \n",
    "from bs4 import BeautifulSoup   # pour la collection\n",
    "from text_to_num import alpha2digit  # pour remplacer les nombres ecrivent en lettres en chiffre \n",
    "import spacy # pour le traitement de texte en decoupant le texte en token \n",
    "import re  # pour supprimer les espaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Keur Maba Diakhou', 'Mbane', 'Matam', 'Sagatta Dioloff', 'Gainte Pathé', 'Birkelane', 'Pata', 'Pout', 'Paoscoto', 'Dangalma', 'Kab Gaye', 'Yop', 'Keur Socé', 'Réfane', 'Pété Ouarack', 'Gathiary', 'Dinguiraye', 'Kaffrine', 'Thiamène Djolof', 'Santhiaba Manjacque', 'Dougue', 'Dankh Sène', 'Kahi', 'Loul Séssène', 'Taïba Niassène', 'Fissel', 'Pire Gourèye', 'Keur Momar Sarr', 'Ngabou Dalla', 'Diawara', 'Gainthe Kaye', 'Dioulacolon', 'Sagatta Dioloff', 'Ngayokhème', 'Barkedji', 'Ndiaganiao', 'Bandafassi', 'Patar', 'Nguidillé', 'Mbour', 'Gamadji Sarré', 'Ida Mouride', 'Foundiougne', 'Tomboronkoto', 'Diattacounda', 'Labgar', 'Wack Ngouna', 'Taïf', 'Ogo', 'Gaé', 'Tenghory', 'Waoundé', 'Kandia', 'Lambaye', 'Civol', 'Communautés rurales', 'Léona', 'Séssène', 'Djibabouya', 'Ourossogui', 'Fafacourou', 'Oulampane', 'Kahone', 'Ndioumane Taiba', 'Dialacoto', 'Aéré', 'Médina Yoy Foulah', 'Missirah', 'Tassette', 'Saly Escale', 'Sakar', 'Gniby', 'Fadiouth', 'Suelle', 'Kounkané', 'Ndramé Escale', 'Grand Dakar', 'Méouane', 'Diakhao', 'Médina Dakhar', 'Bona', 'Camaracounda', 'Dendey Gouyegui', 'Bassoul', 'Mpal', 'Malicounda', 'Enampor', 'Sindian', 'Linkéring', 'Communes', 'Boulal', 'Djanké Souf', 'Niaguis', 'Nghoye', 'Dabo', 'Bandafassi', 'Diourbel', 'Benet', 'Sinthiou Bamambé', 'Maka', 'Mbar', 'Diossong', 'Fongolembi', 'Lougré', 'Prokhane', 'Patar Lia', 'Méckhé', 'Bargny', 'Saint', 'Nabbadji Civol', 'Ndande', 'Ndiebel', 'Ballingore', 'Boutoupa', 'Sinthiou Bamambé', 'Kamb', 'Guinguinéo', 'Salikégné', 'Ndiatbé', 'Ndiagne', 'Fanaye', 'Dabo', 'Mampatim', 'Méouane', 'Mangagoulack', 'Thiès', 'Goudomp', 'Thionck', 'Ourour', 'Sinthiou Malèm', 'Niomré', 'Podor', 'Bani Israèl', 'Keur Moussa', 'Némataba', 'Ngoudiane', 'Ndiognick', 'Lao', 'Ndiayène Pendao', 'Darou Salam Typ', 'Mbane', 'Madina', 'Dakar', 'Bounkiling', 'Diokoul Mbelbouck', 'Touba Fall', 'Makacoulibantang', 'Nioro du rip', 'Ouadiour', 'Keur Ngalgou', 'Plateau', 'Koumpentoum', 'Notto', 'Niaguis', 'Kouthiaba Wolof', 'Keur Samba Kane', 'Barkédji', 'Nbayène', 'Dahra', 'Yop', 'Sokone', 'Orkadiéré', 'Moudéry', 'Gandé', 'Passy', 'Rosso', 'Ngayène', 'Kael', 'Kanel', 'Dodji', 'Djirnda', 'Ndoulo', 'Thilmakha', 'Tessékéré Forage', 'Koussanar', 'Taïf', 'Kathiotte', 'Nganda', 'Ndiaffate', 'Kéniaba', 'Niamone', 'Diouloulou', 'Djibidione', 'Colobane', 'Kafountine', 'Gade Escale', 'Gamadji Sarré', 'Louis', 'Ouassadou', 'Saré Bidji', 'Ndioum Ngainthe', 'Keur Maka', 'Kédougou', 'Mbadiane', 'Thiaré', 'Agnam', 'Mabo', 'Birkelane', 'Fatick', 'Darou Mousty', 'Séssène', 'Maka', 'Ouonck', 'Ribot Escale', 'Thiolly', 'Darou Mousty', 'Djirédji', 'Diaroumé', 'Touba Mosquée', 'Gandon', 'Bakel', 'Notto', 'Darou Marnane', 'Malem Hodar', 'Toubacouta', 'Sakately', 'Keur Moussa', 'Thiékène', 'Touba Mboul', 'Kael', 'Sagatta', 'Ranérou', 'Kolda', 'Touba Toul', 'Diaoulé', 'Bandègne Ouolof', 'Belé', 'Sansamba', 'Khossanto', 'Sinthiou Fissa', 'Thiaroye', 'Fimela', 'Ngogom', 'Médinatoul Salam II', 'Gandiaye', 'Orkadiéré', 'Tattaguine', 'Thillé Boubacar', 'Gossas', 'Linguère', 'Yène', 'Oukout', 'Ndiob', 'Gagnick', 'Saraya', 'Thiakar', 'Lour Escale', 'Wourour Sidy', 'Darou Minam 2', 'Joal', 'Pikine', 'Diattacounda', 'Sébikhotane', 'Nguéniène', 'Ranérou', 'Médina Yoro Foulah', 'Madina Foulbé', 'Syer', 'Dagoudane', 'Thiel', 'Ngathe Naoudé', 'Sam Yabal', 'Tendouck', 'Gawane', 'Diofor', 'Sibassor', 'Niakhène', 'Fissel', 'Ndoga Boubacar', 'Médina Sabakh', 'Niakhar', 'Fandène', 'Bambali', 'Ndoffane', 'Ndoyenne', 'Adéane', 'Keur Saloum Diané', 'Aouré', 'Kébémer', 'Touré Mbonde', 'Ndiéné Lagane', 'Pékesse', 'Thiénaba', 'Mbacke', 'Missirah Sirimana', 'Koumpentoum', 'Karantamba', 'Latmingué', 'Bonconto', 'Dimboli', 'Goudiry', 'Niagha', 'Diouroup', 'Nganda', 'Diokoul Diawrigne', 'Sadio', 'Thieppe', 'Sakal', 'Galoya Toucouleur', 'Médina Baffé', 'Dagana', 'Thiomby', 'Sénégal', 'Bignona', 'Niassia', 'Gare', 'Ziguinchor', 'Diakhao', 'Cabrousse', 'Malem Hodar', 'Paroumba', 'Nguer Malal', 'Bijini', 'Malem Niani', 'Ndiayène Sirah', 'Tocky', 'Patar', 'Ndondol', 'Koul', 'Ndiago', 'Tambacounda', 'Salémata', 'Pété', 'Civol', 'Guédé Village', 'Ogo', 'Diégoune', 'Mbadakhoune', 'Sangalkam', 'Mbéllacadio', 'Mboss', 'Kidira', 'Bamba Thialène', 'Semmé', 'Parcelles Assainies', 'Ndiamacouta', 'Coumbacara', 'Vélingara', 'Kayemor', 'Bokidiawé', 'Dabia', 'Tivaouane', 'Ndande', 'Niakhène', 'Sandiara', 'Sédhiou', 'Géoul', 'Bagadadji', 'Déali', 'Sindia', 'Sakal', 'Netté Boulou', 'Bala', 'Kanène Ndiob', 'Dianah Malari', 'Louga', 'Oussouye', 'Mont Rolland', 'Djibanar', 'Kartiack', 'Djibabouya', 'Toubacouta', 'Diouloulou', 'Ross', 'Ngoye', 'Marsassoum', 'Saré Coly Salé', 'Diarrère', 'Rao', 'Djemberring', 'Koumbal', 'Ndorma', 'Taiba Moutoupha', 'Essyl', 'Loro', 'Bokiladji', 'Ngandiouf', 'Gassane', 'Almadies', 'Sindian', 'Dionewar', 'Tattaguine', 'Ndame', 'Golléré', 'Mboumba', 'Rufisque', 'Colobane', 'Sarr', 'Djignaki', 'Tanaff', 'Taïba Ndiaye', 'Kahène', 'Ndiédieng', 'Fimela', 'Rufisque', 'Ndiédieng', 'Sagatta Fall', 'Saraya', 'Thiadiaye', 'Niayes', 'Djilasse', 'Bambey', 'Diama', 'Sadatou', 'Tanaff', 'Samine Escale', 'Keur Samba Guèye', 'Bonconto', 'Sinthiang Koundara', 'Kelle Guèye', 'Tankanto Escale', 'Arrondissements', 'Mlomp', 'Dakar', 'Wack Ngouna', 'Thiamène Cayor', 'Keur Momar Sarr', 'Madina', 'Médina Gounass', 'Mboro', 'Boulel', 'Kalibantang', 'Djilor', 'Mboula', 'Bounkiling', 'Niakhar', 'Vélingara', 'Ndindy', 'Khombole', 'Lambaye', 'Mbadakhoune', 'Nguène', 'Djilor', 'Saldé', 'Dioulacolon', 'Diendé', 'Nioro Allassane Tall', 'Thilogne', 'Palmarin Facao', 'Dodji', 'Koussanar', 'Richard Toll', 'Kothiary', 'Médina El Hadj', 'Thiargny', 'Guediawaye', 'Kaolack', 'Diamniadio', 'Dodel', 'Ndoulo', 'Sangalkam', 'Niodior', 'Ouarkhokh', 'Simbandi Brassou', 'Mbédiène', 'Thiénaba', 'Missirah', 'Baba Garage', 'Sindia', 'Koulor', 'Fongolembi', 'Ngoye', 'Ouadiour', 'Mlomp', 'Nguékhokh', 'Oréfondé', 'Goudiry', 'Médina Sabakh', 'Pambal', 'Keur Madiabel', 'Gabou', 'Diender Geudj', 'Paoscoto', 'Pakour', 'Coki', 'Tenghory', 'Médina Dakhar', 'Salémata', 'Coki', 'Notto Gouye', 'Niassia', 'Baba Garage', 'Dya', 'Coubalan', 'Ballou', 'Ndindy', 'Béthio', 'Makacoulibantang', 'Loudia Ouoloff', 'Ngohé', 'Touba Mérina', 'Mbeuleukhé', 'Chérif Lo', 'Koungheul', 'Yang Yang', 'Ndioum', 'Kounkané', 'Diendé', 'Mbediène', 'Niaro', 'Guédiawaye']\n"
     ]
    }
   ],
   "source": [
    "# Scraper les communes, les arrondissements et les villages du Senegal\n",
    "\n",
    "url_ = \"https://www.planete-senegal.com/senegal/decoupage_administratif_senegal.php\"\n",
    "\n",
    "reponse = requests.get(url_)\n",
    "\n",
    "if reponse.status_code == 200:\n",
    "    #recuperer le code html\n",
    "    html = reponse.text\n",
    "    \n",
    "    with open(\"Departement_Senegal.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html)\n",
    "    \n",
    "    communes, arrondissements, villages = [], [], []\n",
    "     \n",
    "    \n",
    "    # scraper\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # Scraper tous les communes, les arrondissements et les villages du Senegal\n",
    "    all_content_page = soup.find(\"table\", width = \"100%\", border = \"1\")\n",
    "    all_communes = all_content_page.find_all(\"td\", width = \"20%\")\n",
    "    all_arrondissement = all_content_page.find_all(\"td\", width = \"26%\")\n",
    "    all_villages = all_content_page.find_all(\"td\", width = \"39%\")\n",
    "    \n",
    "    # Les communes\n",
    "    for commune in all_communes:\n",
    "        communes.append(commune.text.strip().replace(\"\\r\\n\", \"\"))\n",
    "        \n",
    "    # Les arrondissements\n",
    "    for arrondissement in all_arrondissement:\n",
    "        arrondissements.append(arrondissement.text.strip().replace(\"\\r\\n\", \"\"))\n",
    "        \n",
    "    # Les villages\n",
    "    for village in all_villages:\n",
    "        villages.append(village.text.strip().replace(\"\\r\\n\", \"\"))\n",
    "        \n",
    "    # Remplacer les espaces multiples par un seul espace\n",
    "    resultat_communes_propres = [re.sub(r'\\s+', ' ', commune) for commune in communes]\n",
    "    resultat_arrondissement_propres = [re.sub(r'\\s+', ' ', arrondissement) for arrondissement in arrondissements]\n",
    "    resultat_villages_propres = [re.sub(r'\\s+', ' ', village) for village in villages]\n",
    "    \n",
    "    \n",
    "    # Separer tous les communes en supprimant le caractere \"-\"\n",
    "    communes_propres = []\n",
    "    for com in resultat_communes_propres:\n",
    "        if com != \"Rosso-Sénégal\":\n",
    "            communes_propres.extend(com.strip().split(\"-\"))\n",
    "            \n",
    "           \n",
    "    # Separer tous les arrondissements en supprimant le caractere \"-\"\n",
    "    arrondissements_propres = []\n",
    "    for arron in resultat_arrondissement_propres:\n",
    "        if arron not in [\"Dakar-Plateau\", \"Ross-Béthio\", \"Cas-cas\"]:\n",
    "            arrondissements_propres.extend(arron.strip().split(\"-\"))\n",
    "            \n",
    "            \n",
    "    # Separer tous les villages en supprimant le caractere \"-\"\n",
    "    villages_propres = []\n",
    "    for villa in resultat_villages_propres:\n",
    "        villages_propres.extend(villa.strip().split(\"-\"))\n",
    "    \n",
    "    # suppresion des cases vides    \n",
    "    villages_propres = list(filter(None, villages_propres))\n",
    "     \n",
    "     \n",
    "    # Regroupement communes, les arrondissements et les villages du Senegal\n",
    "    senegal = set(communes_propres) | set(arrondissements_propres) | set(villages_propres)\n",
    "    senegal = list(senegal)\n",
    "    \n",
    "    # suppresion des espaces vides\n",
    "    senegal = [n.strip() for n in senegal]\n",
    "    \n",
    "    # Enrichir la liste senegal\n",
    "    senegal.extend((\"Niaro\", \"Guédiawaye\"))\n",
    "    \n",
    "    print(senegal)\n",
    "    \n",
    "else:\n",
    "    print(\"ERREUR:\", reponse.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "# Constantes\n",
    "URL = \"https://www.senenews.com/tag/accident\"\n",
    "\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:126.0) Gecko/20100101 Firefox/126.0\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_html(url, headers):\n",
    "    \"\"\"Recuper le contenu HTML de l'url.\"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(\"ERREUR:\", response.status_code)\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html_to_file(html, filename):\n",
    "    \"\"\"Sauvarge le code HTML dans un fichier.\"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html):\n",
    "    \"\"\"Parse contenu HTML en utilisant BeautifulSoup.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_gravity(nombre_morts):\n",
    "    \"\"\"Determine la gravite de l'accident.\"\"\"\n",
    "    if nombre_morts > 0:\n",
    "        return \"grave\"\n",
    "    else:\n",
    "        return \"non grave\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(doc):\n",
    "    \"\"\"Extraction des informations sur les textes.\"\"\"\n",
    "    lieu_accident = None\n",
    "    nombre_morts = 0\n",
    "    nombre_blesses = 0\n",
    "    \n",
    "    def extract_numbers(token):\n",
    "        prev_token = token.nbor(-1) \n",
    "        if prev_token.like_num:\n",
    "            return 1 if prev_token.text.lower() == \"un\" else int(prev_token.text)\n",
    "        return 0\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in senegal:\n",
    "            lieu_accident = token.text\n",
    "        elif \"mort\" in token.text.lower():\n",
    "            nombre_morts = extract_numbers(token)\n",
    "        elif \"blessé\" in token.text.lower():\n",
    "            nombre_blesses = extract_numbers(token)\n",
    "    \n",
    "    if not lieu_accident:\n",
    "        lieu_accident = None\n",
    "    \n",
    "    return lieu_accident, nombre_morts, nombre_blesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour récupérer la date à partir du lien de l'article\n",
    "def get_article_date(article_url):\n",
    "    \"\"\" Recupere la date à partir du lien\"\"\"\n",
    "    response = requests.get(article_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Trouver la balise <span class=\"date updated\">\n",
    "    date_span = soup.find('span', class_='date updated')\n",
    "    \n",
    "    if date_span:\n",
    "        return date_span.text.strip()  # Retourner le texte contenu dans la balise\n",
    "    else:\n",
    "        return None  # Retourner None si la balise n'est pas trouvée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour récupérer les titres d'articles contenant le mot \"accident\" et leur date associée\n",
    "def get_accident_articles_with_dates(soup):\n",
    "   \n",
    "    articles_with_dates = []\n",
    "\n",
    "    # Trouver tous les liens des articles\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        article_url = link['href']\n",
    "        \n",
    "        # Vérifier si le titre de l'article contient le mot \"accident\"\n",
    "        if 'accident' in link.text.lower():\n",
    "            # Trouver la date associée à cet article\n",
    "            date = get_article_date(article_url)\n",
    "            if date:\n",
    "                articles_with_dates.append({'title': link.text.strip(), 'date': date})\n",
    "                \n",
    "        # Ajouter un délai entre chaque requête\n",
    "        #time.sleep(2)  # Attendre 2 secondes entre les requêtes            \n",
    "\n",
    "    return articles_with_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour supprimer les heures au niveau de la date\n",
    "def remove_time(date_str):\n",
    "    \"\"\"Remove time from a datetime string.\"\"\"\n",
    "    if ' à ' in date_str:\n",
    "        return date_str.split(' à ')[0]\n",
    "    return date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## PARTIE A ADAPTER POUR CHAQUE SITE #################################################\n",
    "\n",
    "def extract_data(soup):\n",
    "    \"\"\"Extract relevant data from parsed HTML.\"\"\"\n",
    "    data = pd.DataFrame(columns=[\"Jour\", \"Lieu\", \"Nombre_victimes\", \"Nombre_blesses\", \"Nombre_morts\", \"Gravite\"])\n",
    "    \n",
    "     # Intégrer la récupération des titres d'articles avec leur date associée\n",
    "    accident_articles_with_dates = get_accident_articles_with_dates(soup) \n",
    "    \n",
    "    for article in accident_articles_with_dates:\n",
    "        # Extraire les informations pertinentes pour chaque article\n",
    "        texte = article['title']\n",
    "        date = remove_time(article['date'])\n",
    "        text = alpha2digit(texte, \"fr\")\n",
    "        doc = nlp(text)\n",
    "        lieu_accident, nombre_morts, nombre_blesses = extract_information(doc)\n",
    "        gravite_accident = determine_gravity(nombre_morts)\n",
    "        \n",
    "        # Ajouter les informations extraites dans le dataframe\n",
    "        new_row = pd.DataFrame([{\n",
    "            \"Jour\" : date,\n",
    "            \"Lieu\": lieu_accident,\n",
    "            \"Nombre_victimes\": nombre_morts + nombre_blesses,\n",
    "            \"Nombre_blesses\": nombre_blesses,\n",
    "            \"Nombre_morts\": nombre_morts,\n",
    "            \"Gravite\": gravite_accident\n",
    "        }])\n",
    "        data = pd.concat([data, new_row], ignore_index=True)\n",
    "    \n",
    "    # Remplacer les valeurs None par \"NA\" dans la colonne \"Lieu\"\n",
    "    data[\"Lieu\"].fillna(\"NA\", inplace=True)\n",
    "    \n",
    "    # Réindexer pour commencer à 1\n",
    "    data.index = range(1, len(data) + 1) \n",
    "    \n",
    "            \n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Jour        Lieu Nombre_victimes Nombre_blesses Nombre_morts  \\\n",
      "1   29/05/2024          NA               0              0            0   \n",
      "2   29/05/2024    Rufisque               0              0            0   \n",
      "3   27/05/2024   Birkelane               9              9            0   \n",
      "4   25/05/2024       Thiès               0              0            0   \n",
      "5   21/05/2024          NA               0              0            0   \n",
      "6   18/05/2024  Marsassoum               0              0            0   \n",
      "7   15/05/2024          NA               1              0            1   \n",
      "8   13/05/2024  Guédiawaye               0              0            0   \n",
      "9   13/05/2024          NA               0              0            0   \n",
      "10  10/05/2024          NA               0              0            0   \n",
      "11  08/05/2024          NA               0              0            0   \n",
      "12  07/05/2024  Ziguinchor               0              0            0   \n",
      "13  05/05/2024     Sédhiou               0              0            0   \n",
      "14  04/05/2024          NA               1              0            1   \n",
      "15  03/05/2024     Kaolack               0              0            0   \n",
      "16  02/05/2024       Niaro               0              0            0   \n",
      "17  29/04/2024          NA               0              0            0   \n",
      "18  26/04/2024   Koungheul              22              8           14   \n",
      "19  26/04/2024   Koungheul              14              0           14   \n",
      "20  25/04/2024   Koungheul              60             51            9   \n",
      "21  21/04/2024       Louga               0              0            0   \n",
      "\n",
      "      Gravite  \n",
      "1   non grave  \n",
      "2   non grave  \n",
      "3   non grave  \n",
      "4   non grave  \n",
      "5   non grave  \n",
      "6   non grave  \n",
      "7       grave  \n",
      "8   non grave  \n",
      "9   non grave  \n",
      "10  non grave  \n",
      "11  non grave  \n",
      "12  non grave  \n",
      "13  non grave  \n",
      "14      grave  \n",
      "15  non grave  \n",
      "16  non grave  \n",
      "17  non grave  \n",
      "18      grave  \n",
      "19      grave  \n",
      "20      grave  \n",
      "21  non grave  \n"
     ]
    }
   ],
   "source": [
    "############################# FONCTION PRINCIPALE ###################################\n",
    "\n",
    "def main():\n",
    "    html = fetch_html(URL, HEADERS)  # Entrer l'url et l'entete\n",
    "    \n",
    "    if html:\n",
    "        save_html_to_file(html, \"Accident-Senenews.html\")\n",
    "        soup = parse_html(html) # parse le contenu html\n",
    "        data = extract_data(soup) # extraction des donnees \n",
    "        \n",
    "        print(data) # Affichage de la base de donnees\n",
    "        \n",
    "        # Export data \n",
    "        data.to_excel(\"C:/Users/Mouha/OneDrive/Desktop/MEMOIRE/Code_memoire_mouhamadou_djimba_thiam/scraping_senenew_memoire/data_accident_senegal.xlsx\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEUXIEME PARTIE : NETTOYAGE ET TRAITEMENT DES DONNEES ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
